Архив с проектом airflow_hw, 
внутри него:
шаблон DAG’а (dags/hw_dag.py),
готовый код ML-модели (modules/pipeline.py),
шаблон скрипта для прогноза моделью (modules/predict.py),
данные для обучения и тестирования (data/train, data/test),
пустые папки под сохранение ML-модели и предсказаний.

Создан пайплайн, в котором 2 шага:
pipeline — здесь выполняется функция pipeline,
predict — здесь делается предикт для всех объектов и сохраняется в папку data/predictions.

Для работы сервиса необходимо запустить пайплайн в интерфейсе Airflow и получить предикты модели

Работа с файлами проекта будет зависеть от способа развертывания Airflow:
локально: Airflow живёт в домашней директории 
При запуске DAG результаты будут записываться сразу в папку проекта, дополнительных действий не потребуется

P. S. 
В файле modules/pipeline.py отладочная информация о качестве ML-моделей выводится не через print(), 
а с помощью модуля logging. Благодаря этому, в логах задач в Airflow мы сможем читать всю нужную нам информацию (время, файл и так далее)
